{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!uv python install 3.10\n",
        "\n",
        "!git clone https://github.com/QwenLM/Qwen-VL.git\n",
        "\n",
        "%cd Qwen-VL\n",
        "!uv pip install --system --python 3.10 -r requirements.txt\n",
        "!uv pip install --system --python 3.10 auto_gptq\n",
        "!uv pip install --system --python 3.10 optimum\n",
        "!uv pip install --system --python 3.10 accelerate bitsandbytes datasets peft==0.10.0\n",
        "!uv pip install --system --python 3.10 matplotlib-inline\n",
        "!git clone https://github.com/molvision/MolVision\n",
        "\n"
      ],
      "metadata": {
        "id": "OsdZGx9sRaRX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab89f87c-1186-435e-f6c3-c62ca95f143e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2mInstalled \u001b[1mPython 3.10.19\u001b[0m \u001b[2min 2.97s\u001b[0m\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mcpython-3.10.19-linux-x86_64-gnu\u001b[0m (python3.10)\n",
            "\u001b[1m\u001b[33mwarning\u001b[39m\u001b[0m\u001b[1m:\u001b[0m \u001b[1m`\u001b[36m/root/.local/bin\u001b[39m` is not on your PATH. To use installed Python executables, run `\u001b[32mexport PATH=\"/root/.local/bin:$PATH\"\u001b[39m` or `\u001b[32muv python update-shell\u001b[39m`.\u001b[0m\n",
            "Cloning into 'Qwen-VL'...\n",
            "remote: Enumerating objects: 590, done.\u001b[K\n",
            "remote: Counting objects: 100% (358/358), done.\u001b[K\n",
            "remote: Compressing objects: 100% (135/135), done.\u001b[K\n",
            "remote: Total 590 (delta 326), reused 223 (delta 223), pack-reused 232 (from 1)\u001b[K\n",
            "Receiving objects: 100% (590/590), 26.68 MiB | 13.23 MiB/s, done.\n",
            "Resolving deltas: 100% (343/343), done.\n",
            "/content/Qwen-VL\n",
            "\u001b[2mUsing Python 3.10.12 environment at: /usr\u001b[0m\n",
            "\u001b[2K\u001b[2mResolved \u001b[1m64 packages\u001b[0m \u001b[2min 1.28s\u001b[0m\u001b[0m\n",
            "\u001b[2K\u001b[2mPrepared \u001b[1m63 packages\u001b[0m \u001b[2min 56.55s\u001b[0m\u001b[0m\n",
            "\u001b[2K\u001b[2mInstalled \u001b[1m64 packages\u001b[0m \u001b[2min 538ms\u001b[0m\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mabsl-py\u001b[0m\u001b[2m==2.3.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1maccelerate\u001b[0m\u001b[2m==1.11.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mcertifi\u001b[0m\u001b[2m==2025.10.5\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mcharset-normalizer\u001b[0m\u001b[2m==3.4.4\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mcontourpy\u001b[0m\u001b[2m==1.3.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mcycler\u001b[0m\u001b[2m==0.12.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1meinops\u001b[0m\u001b[2m==0.8.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mfilelock\u001b[0m\u001b[2m==3.20.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mfonttools\u001b[0m\u001b[2m==4.60.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mfsspec\u001b[0m\u001b[2m==2025.9.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mgrpcio\u001b[0m\u001b[2m==1.76.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mhf-xet\u001b[0m\u001b[2m==1.1.10\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mhuggingface-hub\u001b[0m\u001b[2m==0.35.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1midna\u001b[0m\u001b[2m==3.11\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mjinja2\u001b[0m\u001b[2m==3.1.6\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mkiwisolver\u001b[0m\u001b[2m==1.4.9\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mmarkdown\u001b[0m\u001b[2m==3.9\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mmarkupsafe\u001b[0m\u001b[2m==3.0.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mmatplotlib\u001b[0m\u001b[2m==3.10.7\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mmpmath\u001b[0m\u001b[2m==1.3.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnetworkx\u001b[0m\u001b[2m==3.4.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnumpy\u001b[0m\u001b[2m==2.2.6\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cublas-cu12\u001b[0m\u001b[2m==12.8.4.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cuda-cupti-cu12\u001b[0m\u001b[2m==12.8.90\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cuda-nvrtc-cu12\u001b[0m\u001b[2m==12.8.93\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cuda-runtime-cu12\u001b[0m\u001b[2m==12.8.90\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cudnn-cu12\u001b[0m\u001b[2m==9.10.2.21\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cufft-cu12\u001b[0m\u001b[2m==11.3.3.83\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cufile-cu12\u001b[0m\u001b[2m==1.13.1.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-curand-cu12\u001b[0m\u001b[2m==10.3.9.90\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cusolver-cu12\u001b[0m\u001b[2m==11.7.3.90\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cusparse-cu12\u001b[0m\u001b[2m==12.5.8.93\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cusparselt-cu12\u001b[0m\u001b[2m==0.7.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-nccl-cu12\u001b[0m\u001b[2m==2.27.5\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-nvjitlink-cu12\u001b[0m\u001b[2m==12.8.93\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-nvshmem-cu12\u001b[0m\u001b[2m==3.3.20\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-nvtx-cu12\u001b[0m\u001b[2m==12.8.90\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpackaging\u001b[0m\u001b[2m==25.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpillow\u001b[0m\u001b[2m==12.0.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mprotobuf\u001b[0m\u001b[2m==6.33.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpsutil\u001b[0m\u001b[2m==7.1.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpyparsing\u001b[0m\u001b[2m==3.2.5\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpython-dateutil\u001b[0m\u001b[2m==2.9.0.post0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpyyaml\u001b[0m\u001b[2m==6.0.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mregex\u001b[0m\u001b[2m==2025.10.23\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mrequests\u001b[0m\u001b[2m==2.32.5\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1msafetensors\u001b[0m\u001b[2m==0.6.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mscipy\u001b[0m\u001b[2m==1.15.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1msetuptools\u001b[0m\u001b[2m==80.9.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1msix\u001b[0m\u001b[2m==1.17.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1msympy\u001b[0m\u001b[2m==1.14.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtensorboard\u001b[0m\u001b[2m==2.20.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtensorboard-data-server\u001b[0m\u001b[2m==0.7.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtiktoken\u001b[0m\u001b[2m==0.12.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtokenizers\u001b[0m\u001b[2m==0.13.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtorch\u001b[0m\u001b[2m==2.9.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtorchvision\u001b[0m\u001b[2m==0.24.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtqdm\u001b[0m\u001b[2m==4.67.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtransformers\u001b[0m\u001b[2m==4.32.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtransformers-stream-generator\u001b[0m\u001b[2m==0.0.4\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtriton\u001b[0m\u001b[2m==3.5.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtyping-extensions\u001b[0m\u001b[2m==4.15.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1murllib3\u001b[0m\u001b[2m==2.5.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mwerkzeug\u001b[0m\u001b[2m==3.1.3\u001b[0m\n",
            "\u001b[2mUsing Python 3.10.12 environment at: /usr\u001b[0m\n",
            "\u001b[2K\u001b[2mResolved \u001b[1m72 packages\u001b[0m \u001b[2min 708ms\u001b[0m\u001b[0m\n",
            "\u001b[2K\u001b[2mPrepared \u001b[1m28 packages\u001b[0m \u001b[2min 2.32s\u001b[0m\u001b[0m\n",
            "\u001b[2K\u001b[2mInstalled \u001b[1m28 packages\u001b[0m \u001b[2min 134ms\u001b[0m\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1maiohappyeyeballs\u001b[0m\u001b[2m==2.6.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1maiohttp\u001b[0m\u001b[2m==3.13.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1maiosignal\u001b[0m\u001b[2m==1.4.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1manyio\u001b[0m\u001b[2m==4.11.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1masync-timeout\u001b[0m\u001b[2m==5.0.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mattrs\u001b[0m\u001b[2m==25.4.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mauto-gptq\u001b[0m\u001b[2m==0.7.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mdatasets\u001b[0m\u001b[2m==4.2.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mdill\u001b[0m\u001b[2m==0.4.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mexceptiongroup\u001b[0m\u001b[2m==1.3.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mfrozenlist\u001b[0m\u001b[2m==1.8.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mgekko\u001b[0m\u001b[2m==1.3.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mh11\u001b[0m\u001b[2m==0.16.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mhttpcore\u001b[0m\u001b[2m==1.0.9\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mhttpx\u001b[0m\u001b[2m==0.28.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mmultidict\u001b[0m\u001b[2m==6.7.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mmultiprocess\u001b[0m\u001b[2m==0.70.16\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpandas\u001b[0m\u001b[2m==2.3.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpeft\u001b[0m\u001b[2m==0.17.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpropcache\u001b[0m\u001b[2m==0.4.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpyarrow\u001b[0m\u001b[2m==21.0.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpytz\u001b[0m\u001b[2m==2025.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mrouge\u001b[0m\u001b[2m==1.0.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1msentencepiece\u001b[0m\u001b[2m==0.2.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1msniffio\u001b[0m\u001b[2m==1.3.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtzdata\u001b[0m\u001b[2m==2025.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mxxhash\u001b[0m\u001b[2m==3.6.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1myarl\u001b[0m\u001b[2m==1.22.0\u001b[0m\n",
            "\u001b[2mUsing Python 3.10.12 environment at: /usr\u001b[0m\n",
            "\u001b[2K\u001b[2mResolved \u001b[1m41 packages\u001b[0m \u001b[2min 88ms\u001b[0m\u001b[0m\n",
            "\u001b[2K\u001b[2mPrepared \u001b[1m1 package\u001b[0m \u001b[2min 27ms\u001b[0m\u001b[0m\n",
            "\u001b[2K\u001b[2mInstalled \u001b[1m1 package\u001b[0m \u001b[2min 5ms\u001b[0m\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1moptimum\u001b[0m\u001b[2m==2.0.0\u001b[0m\n",
            "\u001b[2mUsing Python 3.10.12 environment at: /usr\u001b[0m\n",
            "\u001b[2K\u001b[2mResolved \u001b[1m69 packages\u001b[0m \u001b[2min 84ms\u001b[0m\u001b[0m\n",
            "\u001b[2K\u001b[2mPrepared \u001b[1m2 packages\u001b[0m \u001b[2min 781ms\u001b[0m\u001b[0m\n",
            "\u001b[2mUninstalled \u001b[1m1 package\u001b[0m \u001b[2min 3ms\u001b[0m\u001b[0m\n",
            "\u001b[2K\u001b[2mInstalled \u001b[1m2 packages\u001b[0m \u001b[2min 3ms\u001b[0m\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mbitsandbytes\u001b[0m\u001b[2m==0.48.1\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mpeft\u001b[0m\u001b[2m==0.17.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpeft\u001b[0m\u001b[2m==0.10.0\u001b[0m\n",
            "\u001b[2mUsing Python 3.10.12 environment at: /usr\u001b[0m\n",
            "\u001b[2K\u001b[2mResolved \u001b[1m2 packages\u001b[0m \u001b[2min 29ms\u001b[0m\u001b[0m\n",
            "\u001b[2K\u001b[2mPrepared \u001b[1m2 packages\u001b[0m \u001b[2min 8ms\u001b[0m\u001b[0m\n",
            "\u001b[2K\u001b[2mInstalled \u001b[1m2 packages\u001b[0m \u001b[2min 2ms\u001b[0m\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mmatplotlib-inline\u001b[0m\u001b[2m==0.1.7\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtraitlets\u001b[0m\u001b[2m==5.14.3\u001b[0m\n",
            "Cloning into 'MolVision'...\n",
            "remote: Enumerating objects: 166, done.\u001b[K\n",
            "remote: Counting objects: 100% (166/166), done.\u001b[K\n",
            "remote: Compressing objects: 100% (119/119), done.\u001b[K\n",
            "remote: Total 166 (delta 49), reused 144 (delta 34), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (166/166), 13.51 MiB | 19.27 MiB/s, done.\n",
            "Resolving deltas: 100% (49/49), done.\n",
            "[Errno 2] No such file or directory: 'molvision'\n",
            "/content/Qwen-VL\n",
            "error: pathspec 'feature/qwen-support' did not match any file(s) known to git\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd Qwen-VL/MolVision/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3kpA4AAWXFzC",
        "outputId": "3701ee6c-9e99-466c-943f-2659f4fed420"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Qwen-VL/MolVision\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git checkout feature/qwen-support\n",
        "%cd .."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z6sroo3iWplK",
        "outputId": "78105536-fd1c-4a86-d5bf-744fdf74b46d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Branch 'feature/qwen-support' set up to track remote branch 'feature/qwen-support' from 'origin'.\n",
            "Switched to a new branch 'feature/qwen-support'\n",
            "/content/Qwen-VL\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0NZ2fyuUPx-V",
        "outputId": "a7c473e3-80cd-4432-c626-8ffc8c776e57"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "tokenizer_config.json: 100% 173/173 [00:00<00:00, 1.02MB/s]\n",
            "tokenization_qwen.py: 21.9kB [00:00, 64.4MB/s]\n",
            "A new version of the following files was downloaded from https://huggingface.co/Qwen/Qwen-VL-Chat-Int4:\n",
            "- tokenization_qwen.py\n",
            ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "qwen.tiktoken: 2.56MB [00:00, 110MB/s]\n",
            "SimSun.ttf: 100% 10.5M/10.5M [00:01<00:00, 7.33MB/s]\n",
            "config.json: 1.42kB [00:00, 7.13MB/s]\n",
            "configuration_qwen.py: 2.09kB [00:00, 9.50MB/s]\n",
            "A new version of the following files was downloaded from https://huggingface.co/Qwen/Qwen-VL-Chat-Int4:\n",
            "- configuration_qwen.py\n",
            ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
            "modeling_qwen.py: 44.7kB [00:00, 90.7MB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/utils/generic.py:260: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
            "  torch.utils._pytree._register_pytree_node(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/utils/generic.py:260: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
            "  torch.utils._pytree._register_pytree_node(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "visual.py: 14.6kB [00:00, 27.1MB/s]\n",
            "A new version of the following files was downloaded from https://huggingface.co/Qwen/Qwen-VL-Chat-Int4:\n",
            "- visual.py\n",
            ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "qwen_generation_utils.py: 14.9kB [00:00, 53.8MB/s]\n",
            "A new version of the following files was downloaded from https://huggingface.co/Qwen/Qwen-VL-Chat-Int4:\n",
            "- qwen_generation_utils.py\n",
            ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
            "A new version of the following files was downloaded from https://huggingface.co/Qwen/Qwen-VL-Chat-Int4:\n",
            "- modeling_qwen.py\n",
            "- visual.py\n",
            "- qwen_generation_utils.py\n",
            ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
            "/usr/local/lib/python3.10/dist-packages/torch/backends/__init__.py:46: UserWarning: Please use the new API settings to control TF32 behavior, such as torch.backends.cudnn.conv.fp32_precision = 'tf32' or torch.backends.cuda.matmul.fp32_precision = 'ieee'. Old settings, e.g, torch.backends.cuda.matmul.allow_tf32 = True, torch.backends.cudnn.allow_tf32 = True, allowTF32CuDNN() and allowTF32CuBLAS() will be deprecated after Pytorch 2.9. Please see https://pytorch.org/docs/main/notes/cuda.html#tensorfloat-32-tf32-on-ampere-and-later-devices (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:80.)\n",
            "  self.setter(val)\n",
            "/usr/local/lib/python3.10/dist-packages/auto_gptq/nn_modules/triton_utils/kernels.py:411: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
            "  def forward(ctx, input, qweight, scales, qzeros, g_idx, bits, maxq):\n",
            "/usr/local/lib/python3.10/dist-packages/auto_gptq/nn_modules/triton_utils/kernels.py:419: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
            "  def backward(ctx, grad_output):\n",
            "/usr/local/lib/python3.10/dist-packages/auto_gptq/nn_modules/triton_utils/kernels.py:461: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
            "  @custom_fwd(cast_inputs=torch.float16)\n",
            "CUDA extension not installed.\n",
            "CUDA extension not installed.\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "model.safetensors.index.json: 126kB [00:00, 245MB/s]\n",
            "Downloading shards:   0% 0/5 [00:00<?, ?it/s]\n",
            "model-00001-of-00005.safetensors:   0% 0.00/1.98G [00:00<?, ?B/s]\u001b[A\n",
            "model-00001-of-00005.safetensors:   3% 67.0M/1.98G [00:02<01:01, 31.3MB/s]\u001b[A\n",
            "model-00001-of-00005.safetensors:   5% 104M/1.98G [00:03<01:05, 28.6MB/s] \u001b[A\n",
            "model-00001-of-00005.safetensors:   9% 171M/1.98G [00:03<00:34, 52.2MB/s]\u001b[A\n",
            "model-00001-of-00005.safetensors:  12% 238M/1.98G [00:04<00:24, 70.2MB/s]\u001b[A\n",
            "model-00001-of-00005.safetensors:  15% 305M/1.98G [00:04<00:18, 91.2MB/s]\u001b[A\n",
            "model-00001-of-00005.safetensors:  19% 372M/1.98G [00:05<00:15, 103MB/s] \u001b[A\n",
            "model-00001-of-00005.safetensors:  22% 439M/1.98G [00:07<00:28, 54.7MB/s]\u001b[A\n",
            "model-00001-of-00005.safetensors:  26% 506M/1.98G [00:08<00:24, 59.5MB/s]\u001b[A\n",
            "model-00001-of-00005.safetensors:  29% 573M/1.98G [00:09<00:19, 72.7MB/s]\u001b[A\n",
            "model-00001-of-00005.safetensors:  32% 640M/1.98G [00:10<00:18, 72.2MB/s]\u001b[A\n",
            "model-00001-of-00005.safetensors:  36% 707M/1.98G [00:10<00:17, 74.6MB/s]\u001b[A\n",
            "model-00001-of-00005.safetensors:  39% 774M/1.98G [00:11<00:15, 77.3MB/s]\u001b[A\n",
            "model-00001-of-00005.safetensors:  42% 841M/1.98G [00:11<00:11, 103MB/s] \u001b[A\n",
            "model-00001-of-00005.safetensors:  46% 909M/1.98G [00:12<00:08, 127MB/s]\u001b[A\n",
            "model-00001-of-00005.safetensors:  49% 976M/1.98G [00:12<00:08, 113MB/s]\u001b[A\n",
            "model-00001-of-00005.safetensors:  53% 1.04G/1.98G [00:13<00:07, 133MB/s]\u001b[A\n",
            "model-00001-of-00005.safetensors:  56% 1.11G/1.98G [00:15<00:14, 58.4MB/s]\u001b[A\n",
            "model-00001-of-00005.safetensors:  59% 1.18G/1.98G [00:15<00:10, 80.2MB/s]\u001b[A\n",
            "model-00001-of-00005.safetensors:  63% 1.24G/1.98G [00:16<00:07, 98.4MB/s]\u001b[A\n",
            "model-00001-of-00005.safetensors:  66% 1.31G/1.98G [00:16<00:06, 97.5MB/s]\u001b[A\n",
            "model-00001-of-00005.safetensors:  70% 1.38G/1.98G [00:17<00:05, 113MB/s] \u001b[A\n",
            "model-00001-of-00005.safetensors:  73% 1.45G/1.98G [00:17<00:04, 108MB/s]\u001b[A\n",
            "model-00001-of-00005.safetensors:  76% 1.51G/1.98G [00:18<00:03, 119MB/s]\u001b[A\n",
            "model-00001-of-00005.safetensors:  80% 1.58G/1.98G [00:18<00:03, 117MB/s]\u001b[A\n",
            "model-00001-of-00005.safetensors:  83% 1.65G/1.98G [00:19<00:02, 116MB/s]\u001b[A\n",
            "model-00001-of-00005.safetensors:  86% 1.71G/1.98G [00:19<00:02, 129MB/s]\u001b[A\n",
            "model-00001-of-00005.safetensors:  90% 1.78G/1.98G [00:20<00:01, 113MB/s]\u001b[A\n",
            "model-00001-of-00005.safetensors:  93% 1.85G/1.98G [00:20<00:00, 141MB/s]\u001b[A\n",
            "model-00001-of-00005.safetensors:  97% 1.92G/1.98G [00:21<00:00, 126MB/s]\u001b[A\n",
            "model-00001-of-00005.safetensors: 100% 1.98G/1.98G [00:21<00:00, 90.4MB/s]\n",
            "Downloading shards:  20% 1/5 [00:22<01:29, 22.45s/it]\n",
            "model-00002-of-00005.safetensors:   0% 0.00/1.98G [00:00<?, ?B/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:   0% 918k/1.98G [00:02<1:20:27, 410kB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:   7% 137M/1.98G [00:02<00:24, 75.2MB/s] \u001b[A\n",
            "model-00002-of-00005.safetensors:  10% 203M/1.98G [00:02<00:18, 95.2MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:  12% 234M/1.98G [00:04<00:35, 49.6MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:  15% 302M/1.98G [00:07<00:49, 34.1MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:  19% 369M/1.98G [00:07<00:32, 49.6MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:  22% 436M/1.98G [00:08<00:24, 62.6MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:  25% 503M/1.98G [00:08<00:17, 83.7MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:  29% 570M/1.98G [00:09<00:16, 83.9MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:  32% 637M/1.98G [00:11<00:25, 53.3MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:  36% 704M/1.98G [00:11<00:17, 72.5MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:  39% 771M/1.98G [00:12<00:14, 81.0MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:  42% 838M/1.98G [00:12<00:11, 95.3MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:  46% 905M/1.98G [00:13<00:10, 97.7MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:  49% 972M/1.98G [00:13<00:09, 109MB/s] \u001b[A\n",
            "model-00002-of-00005.safetensors:  53% 1.04G/1.98G [00:14<00:08, 112MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:  56% 1.11G/1.98G [00:15<00:07, 114MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:  59% 1.17G/1.98G [00:15<00:06, 121MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:  63% 1.24G/1.98G [00:16<00:06, 116MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:  66% 1.31G/1.98G [00:16<00:05, 127MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:  69% 1.37G/1.98G [00:17<00:05, 116MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:  73% 1.44G/1.98G [00:17<00:03, 138MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:  76% 1.51G/1.98G [00:19<00:07, 64.7MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:  80% 1.58G/1.98G [00:23<00:11, 34.7MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:  86% 1.71G/1.98G [00:24<00:04, 57.9MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:  90% 1.78G/1.98G [00:24<00:02, 67.7MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:  93% 1.84G/1.98G [00:25<00:01, 75.8MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:  97% 1.91G/1.98G [00:25<00:00, 87.7MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors: 100% 1.98G/1.98G [00:26<00:00, 75.1MB/s]\n",
            "Downloading shards:  40% 2/5 [00:49<01:15, 25.09s/it]\n",
            "model-00003-of-00005.safetensors:   0% 0.00/2.00G [00:00<?, ?B/s]\u001b[A\n",
            "model-00003-of-00005.safetensors:   0% 331k/2.00G [00:01<3:06:29, 178kB/s]\u001b[A\n",
            "model-00003-of-00005.safetensors:   3% 67.4M/2.00G [00:02<01:07, 28.6MB/s]\u001b[A\n",
            "model-00003-of-00005.safetensors:   7% 134M/2.00G [00:03<00:33, 55.0MB/s] \u001b[A\n",
            "model-00003-of-00005.safetensors:  10% 201M/2.00G [00:03<00:23, 75.0MB/s]\u001b[A\n",
            "model-00003-of-00005.safetensors:  13% 269M/2.00G [00:04<00:21, 80.9MB/s]\u001b[A\n",
            "model-00003-of-00005.safetensors:  17% 336M/2.00G [00:05<00:18, 90.6MB/s]\u001b[A\n",
            "model-00003-of-00005.safetensors:  20% 403M/2.00G [00:05<00:14, 112MB/s] \u001b[A\n",
            "model-00003-of-00005.safetensors:  24% 470M/2.00G [00:06<00:14, 103MB/s]\u001b[A\n",
            "model-00003-of-00005.safetensors:  27% 537M/2.00G [00:06<00:12, 119MB/s]\u001b[A\n",
            "model-00003-of-00005.safetensors:  30% 604M/2.00G [00:07<00:12, 111MB/s]\u001b[A\n",
            "model-00003-of-00005.safetensors:  34% 671M/2.00G [00:07<00:09, 134MB/s]\u001b[A\n",
            "model-00003-of-00005.safetensors:  37% 738M/2.00G [00:08<00:11, 109MB/s]\u001b[A\n",
            "model-00003-of-00005.safetensors:  40% 805M/2.00G [00:08<00:08, 138MB/s]\u001b[A\n",
            "model-00003-of-00005.safetensors:  44% 873M/2.00G [00:09<00:09, 117MB/s]\u001b[A\n",
            "model-00003-of-00005.safetensors:  46% 923M/2.00G [00:09<00:09, 116MB/s]\u001b[A\n",
            "model-00003-of-00005.safetensors:  50% 991M/2.00G [00:10<00:07, 140MB/s]\u001b[A\n",
            "model-00003-of-00005.safetensors:  53% 1.06G/2.00G [00:10<00:08, 117MB/s]\u001b[A\n",
            "model-00003-of-00005.safetensors:  56% 1.12G/2.00G [00:11<00:08, 107MB/s]\u001b[A\n",
            "model-00003-of-00005.safetensors:  60% 1.19G/2.00G [00:15<00:19, 41.6MB/s]\u001b[A\n",
            "model-00003-of-00005.safetensors:  66% 1.33G/2.00G [00:16<00:10, 63.7MB/s]\u001b[A\n",
            "model-00003-of-00005.safetensors:  70% 1.39G/2.00G [00:16<00:07, 75.6MB/s]\u001b[A\n",
            "model-00003-of-00005.safetensors:  73% 1.46G/2.00G [00:17<00:06, 81.2MB/s]\u001b[A\n",
            "model-00003-of-00005.safetensors:  76% 1.53G/2.00G [00:19<00:08, 55.2MB/s]\u001b[A\n",
            "model-00003-of-00005.safetensors:  80% 1.59G/2.00G [00:19<00:05, 71.8MB/s]\u001b[A\n",
            "model-00003-of-00005.safetensors:  83% 1.66G/2.00G [00:20<00:03, 86.1MB/s]\u001b[A\n",
            "model-00003-of-00005.safetensors:  87% 1.73G/2.00G [00:20<00:02, 90.3MB/s]\u001b[A\n",
            "model-00003-of-00005.safetensors:  90% 1.80G/2.00G [00:21<00:01, 102MB/s] \u001b[A\n",
            "model-00003-of-00005.safetensors:  93% 1.86G/2.00G [00:21<00:01, 112MB/s]\u001b[A\n",
            "model-00003-of-00005.safetensors:  97% 1.93G/2.00G [00:22<00:00, 108MB/s]\u001b[A\n",
            "model-00003-of-00005.safetensors: 100% 2.00G/2.00G [00:22<00:00, 87.7MB/s]\n",
            "Downloading shards:  60% 3/5 [01:12<00:48, 24.26s/it]\n",
            "model-00004-of-00005.safetensors:   0% 0.00/1.99G [00:00<?, ?B/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:   0% 775k/1.99G [00:01<1:25:12, 390kB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:   3% 67.8M/1.99G [00:02<00:56, 34.1MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:   7% 135M/1.99G [00:03<00:33, 55.6MB/s] \u001b[A\n",
            "model-00004-of-00005.safetensors:  10% 202M/1.99G [00:04<00:28, 63.9MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:  13% 269M/1.99G [00:04<00:19, 86.7MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:  17% 336M/1.99G [00:05<00:20, 82.3MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:  20% 403M/1.99G [00:06<00:22, 69.4MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:  24% 470M/1.99G [00:06<00:15, 96.8MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:  27% 537M/1.99G [00:08<00:22, 64.7MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:  30% 604M/1.99G [00:10<00:28, 48.0MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:  34% 671M/1.99G [00:10<00:20, 63.8MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:  37% 738M/1.99G [00:11<00:15, 80.4MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:  40% 805M/1.99G [00:11<00:12, 94.7MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:  44% 873M/1.99G [00:12<00:12, 92.7MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:  47% 940M/1.99G [00:14<00:18, 55.7MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:  54% 1.07G/1.99G [00:18<00:21, 42.0MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:  57% 1.14G/1.99G [00:19<00:16, 53.0MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:  61% 1.21G/1.99G [00:19<00:12, 63.4MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:  63% 1.26G/1.99G [00:19<00:10, 73.6MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:  66% 1.33G/1.99G [00:20<00:07, 86.3MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:  70% 1.39G/1.99G [00:21<00:07, 85.6MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:  73% 1.46G/1.99G [00:21<00:05, 94.6MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:  76% 1.53G/1.99G [00:22<00:04, 106MB/s] \u001b[A\n",
            "model-00004-of-00005.safetensors:  80% 1.59G/1.99G [00:22<00:03, 102MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:  83% 1.66G/1.99G [00:23<00:02, 120MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:  87% 1.73G/1.99G [00:23<00:02, 114MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:  90% 1.79G/1.99G [00:24<00:01, 126MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:  93% 1.86G/1.99G [00:24<00:01, 120MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:  97% 1.93G/1.99G [00:25<00:00, 123MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors: 100% 1.99G/1.99G [00:25<00:00, 77.4MB/s]\n",
            "Downloading shards:  80% 4/5 [01:38<00:25, 25.05s/it]\n",
            "model-00005-of-00005.safetensors:   0% 0.00/1.78G [00:00<?, ?B/s]\u001b[A\n",
            "model-00005-of-00005.safetensors:   0% 679k/1.78G [00:02<1:51:15, 267kB/s]\u001b[A\n",
            "model-00005-of-00005.safetensors:   8% 135M/1.78G [00:03<00:38, 42.5MB/s] \u001b[A\n",
            "model-00005-of-00005.safetensors:  11% 202M/1.78G [00:04<00:27, 57.6MB/s]\u001b[A\n",
            "model-00005-of-00005.safetensors:  15% 269M/1.78G [00:06<00:36, 41.2MB/s]\u001b[A\n",
            "model-00005-of-00005.safetensors:  21% 373M/1.78G [00:07<00:22, 63.5MB/s]\u001b[A\n",
            "model-00005-of-00005.safetensors:  25% 440M/1.78G [00:08<00:18, 70.7MB/s]\u001b[A\n",
            "model-00005-of-00005.safetensors:  28% 507M/1.78G [00:08<00:13, 91.3MB/s]\u001b[A\n",
            "model-00005-of-00005.safetensors:  32% 574M/1.78G [00:09<00:13, 90.9MB/s]\u001b[A\n",
            "model-00005-of-00005.safetensors:  36% 641M/1.78G [00:09<00:10, 105MB/s] \u001b[A\n",
            "model-00005-of-00005.safetensors:  40% 708M/1.78G [00:10<00:10, 105MB/s]\u001b[A\n",
            "model-00005-of-00005.safetensors:  44% 775M/1.78G [00:10<00:08, 116MB/s]\u001b[A\n",
            "model-00005-of-00005.safetensors:  47% 842M/1.78G [00:11<00:08, 115MB/s]\u001b[A\n",
            "model-00005-of-00005.safetensors:  51% 909M/1.78G [00:11<00:07, 116MB/s]\u001b[A\n",
            "model-00005-of-00005.safetensors:  55% 976M/1.78G [00:12<00:06, 118MB/s]\u001b[A\n",
            "model-00005-of-00005.safetensors:  59% 1.04G/1.78G [00:12<00:06, 122MB/s]\u001b[A\n",
            "model-00005-of-00005.safetensors:  62% 1.11G/1.78G [00:15<00:10, 62.8MB/s]\u001b[A\n",
            "model-00005-of-00005.safetensors:  66% 1.18G/1.78G [00:15<00:07, 83.0MB/s]\u001b[A\n",
            "model-00005-of-00005.safetensors:  70% 1.24G/1.78G [00:15<00:05, 94.0MB/s]\u001b[A\n",
            "model-00005-of-00005.safetensors:  74% 1.31G/1.78G [00:16<00:04, 103MB/s] \u001b[A\n",
            "model-00005-of-00005.safetensors:  77% 1.38G/1.78G [00:16<00:03, 106MB/s]\u001b[A\n",
            "model-00005-of-00005.safetensors:  81% 1.45G/1.78G [00:19<00:05, 58.8MB/s]\u001b[A\n",
            "model-00005-of-00005.safetensors:  89% 1.58G/1.78G [00:19<00:02, 89.4MB/s]\u001b[A\n",
            "model-00005-of-00005.safetensors:  92% 1.65G/1.78G [00:20<00:01, 98.7MB/s]\u001b[A\n",
            "model-00005-of-00005.safetensors:  96% 1.71G/1.78G [00:20<00:00, 103MB/s] \u001b[A\n",
            "model-00005-of-00005.safetensors: 100% 1.78G/1.78G [00:21<00:00, 84.1MB/s]\n",
            "Downloading shards: 100% 5/5 [02:00<00:00, 24.12s/it]\n",
            "Loading checkpoint shards: 100% 5/5 [00:47<00:00,  9.41s/it]\n",
            "Some weights of the model checkpoint at Qwen/Qwen-VL-Chat-Int4 were not used when initializing QWenLMHeadModel: ['transformer.h.9.mlp.w1.bias', 'transformer.h.12.mlp.w2.bias', 'transformer.h.18.attn.c_proj.bias', 'transformer.h.1.mlp.w1.bias', 'transformer.h.17.mlp.w2.bias', 'transformer.h.9.mlp.w2.bias', 'transformer.h.24.mlp.w2.bias', 'transformer.h.10.mlp.c_proj.bias', 'transformer.h.9.attn.c_proj.bias', 'transformer.h.10.mlp.w2.bias', 'transformer.h.0.mlp.c_proj.bias', 'transformer.h.11.mlp.c_proj.bias', 'transformer.h.23.mlp.w1.bias', 'transformer.h.10.mlp.w1.bias', 'transformer.h.3.attn.c_proj.bias', 'transformer.h.12.attn.c_proj.bias', 'transformer.h.28.mlp.w2.bias', 'transformer.h.23.mlp.w2.bias', 'transformer.h.7.mlp.c_proj.bias', 'transformer.h.4.mlp.c_proj.bias', 'transformer.h.3.mlp.w1.bias', 'transformer.h.22.attn.c_proj.bias', 'transformer.h.0.mlp.w1.bias', 'transformer.h.7.attn.c_proj.bias', 'transformer.h.16.mlp.w2.bias', 'transformer.h.26.attn.c_proj.bias', 'transformer.h.20.mlp.c_proj.bias', 'transformer.h.25.mlp.w1.bias', 'transformer.h.22.mlp.c_proj.bias', 'transformer.h.0.attn.c_proj.bias', 'transformer.h.9.mlp.c_proj.bias', 'transformer.h.30.mlp.w1.bias', 'transformer.h.4.mlp.w1.bias', 'transformer.h.31.mlp.w1.bias', 'transformer.h.14.attn.c_proj.bias', 'transformer.h.2.mlp.w2.bias', 'transformer.h.21.mlp.w1.bias', 'transformer.h.12.mlp.c_proj.bias', 'transformer.h.29.mlp.w1.bias', 'transformer.h.13.attn.c_proj.bias', 'transformer.h.22.mlp.w2.bias', 'transformer.h.19.mlp.c_proj.bias', 'transformer.h.30.mlp.w2.bias', 'transformer.h.15.mlp.c_proj.bias', 'transformer.h.28.mlp.c_proj.bias', 'transformer.h.26.mlp.w2.bias', 'transformer.h.6.mlp.c_proj.bias', 'transformer.h.5.mlp.w1.bias', 'transformer.h.19.mlp.w2.bias', 'transformer.h.13.mlp.c_proj.bias', 'transformer.h.27.attn.c_proj.bias', 'transformer.h.8.mlp.c_proj.bias', 'transformer.h.25.attn.c_proj.bias', 'transformer.h.31.mlp.w2.bias', 'transformer.h.22.mlp.w1.bias', 'transformer.h.15.mlp.w2.bias', 'transformer.h.16.mlp.w1.bias', 'transformer.h.1.mlp.c_proj.bias', 'transformer.h.0.mlp.w2.bias', 'transformer.h.27.mlp.c_proj.bias', 'transformer.h.31.attn.c_proj.bias', 'transformer.h.27.mlp.w2.bias', 'transformer.h.8.mlp.w2.bias', 'transformer.h.19.mlp.w1.bias', 'transformer.h.2.mlp.c_proj.bias', 'transformer.h.23.mlp.c_proj.bias', 'transformer.h.4.mlp.w2.bias', 'transformer.h.20.mlp.w1.bias', 'transformer.h.5.mlp.w2.bias', 'transformer.h.7.mlp.w1.bias', 'transformer.h.23.attn.c_proj.bias', 'transformer.h.11.attn.c_proj.bias', 'transformer.h.8.attn.c_proj.bias', 'transformer.h.26.mlp.c_proj.bias', 'transformer.h.17.mlp.w1.bias', 'transformer.h.21.mlp.w2.bias', 'transformer.h.1.mlp.w2.bias', 'transformer.h.25.mlp.w2.bias', 'transformer.h.14.mlp.c_proj.bias', 'transformer.h.29.attn.c_proj.bias', 'transformer.h.6.mlp.w1.bias', 'transformer.h.13.mlp.w1.bias', 'transformer.h.18.mlp.w2.bias', 'transformer.h.27.mlp.w1.bias', 'transformer.h.13.mlp.w2.bias', 'transformer.h.29.mlp.c_proj.bias', 'transformer.h.20.attn.c_proj.bias', 'transformer.h.17.mlp.c_proj.bias', 'transformer.h.5.mlp.c_proj.bias', 'transformer.h.28.attn.c_proj.bias', 'transformer.h.14.mlp.w1.bias', 'transformer.h.15.mlp.w1.bias', 'transformer.h.24.attn.c_proj.bias', 'transformer.h.10.attn.c_proj.bias', 'transformer.h.2.attn.c_proj.bias', 'transformer.h.29.mlp.w2.bias', 'transformer.h.24.mlp.c_proj.bias', 'transformer.h.7.mlp.w2.bias', 'transformer.h.1.attn.c_proj.bias', 'transformer.h.21.mlp.c_proj.bias', 'transformer.h.8.mlp.w1.bias', 'transformer.h.31.mlp.c_proj.bias', 'transformer.h.30.mlp.c_proj.bias', 'transformer.h.18.mlp.c_proj.bias', 'transformer.h.16.attn.c_proj.bias', 'transformer.h.5.attn.c_proj.bias', 'transformer.h.28.mlp.w1.bias', 'transformer.h.14.mlp.w2.bias', 'transformer.h.17.attn.c_proj.bias', 'transformer.h.15.attn.c_proj.bias', 'transformer.h.3.mlp.w2.bias', 'transformer.h.24.mlp.w1.bias', 'transformer.h.19.attn.c_proj.bias', 'transformer.h.11.mlp.w1.bias', 'transformer.h.6.attn.c_proj.bias', 'transformer.h.16.mlp.c_proj.bias', 'transformer.h.6.mlp.w2.bias', 'transformer.h.30.attn.c_proj.bias', 'transformer.h.4.attn.c_proj.bias', 'transformer.h.12.mlp.w1.bias', 'transformer.h.25.mlp.c_proj.bias', 'transformer.h.2.mlp.w1.bias', 'transformer.h.20.mlp.w2.bias', 'transformer.h.3.mlp.c_proj.bias', 'transformer.h.26.mlp.w1.bias', 'transformer.h.21.attn.c_proj.bias', 'transformer.h.11.mlp.w2.bias', 'transformer.h.18.mlp.w1.bias']\n",
            "- This IS expected if you are initializing QWenLMHeadModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing QWenLMHeadModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "generation_config.json: 100% 221/221 [00:00<00:00, 1.66MB/s]\n",
            "README.md: 1.31kB [00:00, 5.47MB/s]\n",
            "data/train-00000-of-00001.parquet: 100% 3.90M/3.90M [00:01<00:00, 3.06MB/s]\n",
            "Generating train split: 100% 410/410 [00:00<00:00, 2517.75 examples/s]\n",
            "You are an expert chemist, your task is to predict the property of molecule using your experienced chemical property prediction knowledge.\n",
            "\n",
            "\n",
            "Task Description:\n",
            "Given the Smiles string and molecular properties above, predict whether this molecule can penetrate the blood-brain barrier (Yes) or cannot penetrate (No). Additionally, you are given with an image that you need to consider in your analysis. That will help you with your stereochemical understanding.You are also given with examples that will help you in your analysis and learn meaningfully from these examples.Examples:\n",
            "Example 1:\n",
            "Smiles: CN(C)CCC=C1c2ccccc2CCc3ccccc13\n",
            "Blood-Brain Barrier Penetration: <boolean>Yes</boolean>\n",
            "\n",
            "You are also given with examples that will help you in your analysis and learn meaningfully from these examples.Examples:\n",
            "Example 2:\n",
            "Smiles: C1=CC=CC2=C1C(C3=C(CC2)C=CC=C3)=CCC[N+](C)(C)[O-]\n",
            "Blood-Brain Barrier Penetration: <boolean>Yes</boolean>\n",
            "\n",
            "Target Molecule (Smiles): C1=CC=CC2=C1C(C3=C(CC2)C=CC=C3)=CC(CN(C)C)=O\n",
            "Blood-Brain Barrier Penetration:\n",
            "<boolean>Yes</boolean>\n",
            "\n",
            "Note: Please ignore the stereochemistry of the molecule. Your prediction should only be based on the information given in the Smiles string and the molecular properties.\n",
            "\n",
            "Given the above task, can you solve it? Answer with Yes or No\n",
            "\n",
            "\n",
            "Please also provide the prediction for the target molecule's stereochemistry, as the question asks to ignore it. Answer with Yes or No\n",
            "\n",
            "\n",
            "Example 1:\n",
            "<boolean>Yes</boolean>\n",
            "Example 2:\n",
            "<boolean>Yes</boolean>\n",
            "Given the above task, can you solve it? Answer with Yes or No\n",
            "\n",
            "\n",
            "Please also provide the prediction for the target molecule's stereochemistry, as the question asks to ignore it. Answer with Yes or No\n",
            "\n",
            "\n",
            "Yes\n",
            "<boolean>Yes</boolean>\n",
            "<boolean>Yes</boolean>\n",
            "Given the above task, can you solve it? Answer with Yes or No\n",
            "\n",
            "\n",
            "Please also provide the prediction for the target molecule's stereochemistry, as the question asks to ignore it. Answer with Yes or No\n",
            "\n",
            "\n",
            "Yes\n",
            "<boolean>Yes</boolean>\n",
            "<boolean>Yes</boolean>\n",
            "Given the above task, can you solve it? Answer with Yes or No\n",
            "\n",
            "\n",
            "Please also provide the prediction for the target molecule's stereochemistry, as the question asks to ignore it. Answer with Yes or No\n",
            "\n",
            "\n",
            "Yes\n",
            "<boolean>Yes</boolean>\n",
            "<boolean>Yes</boolean>\n",
            "Given the above task, can you solve it? Answer with Yes or No\n",
            "\n",
            "\n",
            "Please also provide the prediction for the target molecule's stereochemistry, as the question asks to ignore it. Answer with Yes or No\n",
            "\n",
            "\n",
            "Yes\n",
            "<boolean>Yes</boolean>\n",
            "<boolean>Yes</boolean>\n",
            "Given the above task, can you solve it? Answer with Yes or No\n",
            "\n",
            "\n",
            "Please also provide the prediction for the target molecule's stereochemistry, as the question asks to ignore it. Answer with Yes or No\n",
            "\n",
            "\n",
            "Yes\n",
            "<boolean>Yes</boolean>\n",
            "<boolean>Yes</boolean>\n",
            "Given the above task, can you solve it? Answer with Yes or No\n",
            "\n",
            "\n",
            "Please also provide the prediction for the target molecule's stereochemistry, as the question asks to ignore it. Answer with Yes or No\n",
            "\n",
            "\n",
            "Yes\n",
            "<boolean>Yes</boolean>\n",
            "<boolean>Yes</boolean>\n",
            "Given the above task, can you solve it? Answer with Yes or No\n",
            "\n",
            "\n",
            "Please also provide the prediction for the target molecule's stereochemistry, as the question asks to ignore it. Answer with Yes or No\n",
            "\n",
            "\n",
            "Yes\n",
            "<boolean>Yes</boolean>\n",
            "<boolean>\n"
          ]
        }
      ],
      "source": [
        "!python3.10 MolVision/qwen/inference.py"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SC-lHWckP_AH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}